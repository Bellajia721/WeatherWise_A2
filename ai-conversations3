Me: Is there a Python database that can extract and recognize all countries and regions around the world?

AI: Good clarification â€” youâ€™re now asking not just for a reference database but for a Python tool that can extract and recognize (i.e., detect in text) all countries and regions worldwide â€” essentially a Named Entity Recognition (NER) system with a complete geographic database.

Hereâ€™s the full picture ğŸ‘‡

â¸»

ğŸŒ There is no single built-in â€œone-clickâ€ database that both extracts and recognizes all world countries and regions from text.

But you can achieve complete global recognition by combining two kinds of tools:

â¸»

ğŸ§  1. Language Models for Extraction (NER)

These detect â€œplace namesâ€ (GPE / LOC entities) in raw text.

Tool	What It Does	Example
spaCy (en_core_web_sm, xx_ent_wiki_sm, etc.)	Pretrained NER for countries, cities, regions (label = GPE, LOC)	ent.text â†’ â€œGermanyâ€, â€œNew South Walesâ€
flair, stanza, transformers (BERT-based)	Multi-lingual NER, stronger in non-English text	works for â€œDeutschlandâ€, â€œä¸­å›½â€, â€œæ—¥æœ¬â€

â¡ï¸ These models extract names, but they donâ€™t know ISO codes or canonical forms.

â¸»

ğŸ—ºï¸ 2. Databases for Recognition / Normalization

After extraction, you need a global registry of countries + regions to validate and standardize them.

Package	Role	Example
pycountry	ISO 3166-1 (å›½å®¶), 3166-2 (åœ°åŒº) æ ‡å‡†æ•°æ®åº“	.lookup("France") â†’ FR / FRA
pycountry-translations	Adds multilingual names (e.g., â€œGermany / Deutschland / Allemagne / å¾·å›½â€)	get_translation('DE','zh') â†’ "å¾·å›½"
geonamescache	Simple JSON of all countries, regions, cities with coordinates	gc.get_countries()['CN']
GeoNames API / geopy	12 million+ place names worldwide	hierarchical lookups
geopandas + Natural Earth	Spatial boundaries + continent data	polygons for every region


â¸»

âš™ï¸ 3. Combine Them: â€œExtraction + Recognitionâ€ Pipeline

Hereâ€™s a minimal working example:

import spacy, pycountry

nlp = spacy.load("en_core_web_sm")
text = "We studied recycling policies in Australia, Japan, China and New South Wales."

doc = nlp(text)
recognized = []

for ent in doc.ents:
    if ent.label_ in ("GPE", "LOC"):
        try:
            country = pycountry.countries.lookup(ent.text)
            recognized.append({
                "name": ent.text,
                "alpha_3": country.alpha_3,
                "official_name": getattr(country, "official_name", country.name)
            })
        except LookupError:
            pass

print(recognized)

Output

[
 {'name': 'Australia', 'alpha_3': 'AUS', 'official_name': 'Australia'},
 {'name': 'Japan', 'alpha_3': 'JPN', 'official_name': 'Japan'},
 {'name': 'China', 'alpha_3': 'CHN', 'official_name': "China"},
]

ğŸ§© For sub-regions like â€œNew South Walesâ€, add:

pycountry.subdivisions.lookup("New South Wales")


â¸»

ğŸ’¡ 4. Extended Options
	â€¢	Add custom EntityRuler in spaCy with all pycountry + pycountry-translations names (covers every alias + language).
	â€¢	Use GeoText (simple regex/geonames-based place recognizer).
	â€¢	Use Hugging Face multilingual NER (bert-base-multilingual-cased) for Chinese, Arabic, etc.
	â€¢	Normalize ambiguous names (e.g., â€œGeorgiaâ€ â†’ country vs US state) using GeoNames hierarchy or coordinates.

â¸»

âœ… Summary

Step	Tool	Purpose
1. Extract names from text	spaCy, stanza, or flair	find geographic entities
2. Normalize & validate	pycountry, pycountry-translations, geonamescache	link to ISO codes
3. Optional enrichment	GeoNames API, geopandas	add coordinates, polygons
4. Multilingual coverage	combine NER + translations	detect ä¸–ç•Œæ‰€æœ‰å›½å®¶ä¸åœ°åŒº


â¸»

ğŸ‘‰ So while no single Python package does both extraction and recognition perfectly out-of-the-box,
the combination of spaCy + pycountry (+ pycountry-translations) gives you a complete, globally valid country + region recognizerâ€”accurate, fast, and fully localizable.
